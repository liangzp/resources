{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.3 s, sys: 1min 5s, total: 1min 23s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_cores = -1  # Use all available cores, you can adjust this value based on your system resources\n",
    "\n",
    "# Use joblib to parallelize the reading of files\n",
    "files = pd.concat(Parallel(n_jobs=num_cores, backend='multiprocessing')(delayed(read_file)(file_name) for file_name in files_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.from_pandas(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df.with_columns(temp_df['rec_epoch'].apply(lambda x: datetime.fromtimestamp(x).astimezone(timezone('Asia/Hong_Kong'))).alias('time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    temp_df = temp_df.with_column((A/A.shift(1) - 1).rename(f'A{i}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgraph_objects\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mgo\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexpress\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpx\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpio\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from math import ceil\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "\n",
    "pio.renderers.default = 'notebook'\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe' # or 'colab' or 'iframe' or 'iframe_connected' or '\n",
    "\n",
    "\n",
    "test_cols = list(set(new_cols + ['alpha', 'new_alpha_linear']))\n",
    "start_date = 20210701\n",
    "end_train_date = 20220101\n",
    "sel_freq = 60\n",
    "\n",
    "############################# \n",
    "temp_df_full = temp_df.clone().fill_null(0)\n",
    "temp_df_full = temp_df_full.sort('date')\n",
    "temp_df = temp_df_full.filter(temp_df_full['date']>= start_date)\n",
    "\n",
    "## check terms correlation\n",
    "# Compute the correlation matrix using Polars\n",
    "correlation_matrix = temp_df[new_cols].pearson_corr()\n",
    "column_names = correlation_matrix.columns\n",
    "\n",
    "# np.fill_diagonal(correlation_matrix, 0)\n",
    "\n",
    "# Convert the correlation matrix to a NumPy array\n",
    "# correlation_values = correlation_matrix.to_list()\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', annot_kws={\"size\": 10},  xticklabels=column_names, yticklabels=column_names)\n",
    "\n",
    "# Add title and show the plot\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "print('start to train linear regression model')\n",
    "start_time = time.time()\n",
    "############################# fitter\n",
    "temp_df_train, temp_df_test = temp_df.filter(temp_df['date']<=end_train_date), temp_df.filter(temp_df['date']>end_train_date)\n",
    "X_train, X_test = pl.concat([temp_df_train[new_cols], temp_df_train['alpha'].to_frame()], how = 'horizontal').transpose(), pl.concat([temp_df_test[new_cols], temp_df_test['alpha'].to_frame()], how = 'horizontal').transpose()\n",
    "# X_train, X_test = temp_df_train[new_cols].transpose(), temp_df_test[new_cols].transpose()\n",
    "y_train, y_test = temp_df_train['ret60s'].to_frame().transpose(), temp_df_test['ret60s'].to_frame().transpose()\n",
    "\n",
    "# linear model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "new_alpha = np.vstack([model.predict(X_train), model.predict(X_test)])\n",
    "temp_df = temp_df.with_columns(pl.Series('new_alpha_linear', new_alpha.flatten()))\n",
    "\n",
    "print(f'finish training, use {time.time() - start_time} s')\n",
    "# # ridge model\n",
    "# model = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1])\n",
    "# model.fit(X_train, y_train)\n",
    "# new_alpha = np.vstack([model.predict(X_train), model.predict(X_test)])\n",
    "# temp_df = temp_df.with_columns(pl.Series('new_alpha_ridge', new_alpha.flatten()))\n",
    "\n",
    "\n",
    "#### scatter plots\n",
    "n = len(new_cols)\n",
    "n_perrow = 4\n",
    "fig, axs = plt.subplots(ceil(n/n_perrow), n_perrow, figsize = (12 * n_perrow, 8 * int(n / n_perrow)))\n",
    "for i, term in enumerate(new_cols):\n",
    "    n_row = i // n_perrow\n",
    "    n_col = i - n_row *4 \n",
    "    sns.scatterplot(x = temp_df[term], y = temp_df['ret60s'], label = term, ax = axs[n_row][n_col])\n",
    "    min_, max_ = temp_df[term].min(), temp_df[term].max()  \n",
    "    x = np.linspace(min_, max_)\n",
    "    sns.lineplot(x = x, y = np.zeros_like(x),  ax = axs[n_row][n_col], color = 'r')\n",
    "plt.show()\n",
    "\n",
    "### start to backtest\n",
    "# Group the DataFrame by the \"date\" column\n",
    "groups = temp_df.groupby('date')\n",
    "# Iterate over each group and apply the FR function\n",
    "for i, test_col in enumerate(test_cols):\n",
    "    results = pd.DataFrame()\n",
    "    for group in list(groups):\n",
    "        ret_cols = sorted([col for col in group.columns if col.find('ret')!=-1])\n",
    "        date = int(group['date'].unique()[0])\n",
    "        x = group[test_col].fill_null(0)\n",
    "        result = dict()\n",
    "        result['date'] = date\n",
    "        for ret_col in ret_cols:\n",
    "            y = group[ret_col]\n",
    "            result[f'{test_col}_FR_{ret_col[:-1]}'] = FR(x, y)\n",
    "        result = pd.DataFrame([result])\n",
    "        results = results.append(result, ignore_index=True)\n",
    "    if i == 0:\n",
    "        full_panel = results\n",
    "    else:\n",
    "        full_panel = full_panel.merge(results, left_on = 'date', right_on = 'date')\n",
    "    \n",
    "full_panel = full_panel.sort_values('date').reset_index(drop = True)\n",
    "# Print the results\n",
    "FR_cols = [col for col in full_panel.columns if col.find('FR')!=-1]\n",
    "FR_cum = pd.concat([full_panel['date'], full_panel[FR_cols].cumsum()], axis = 1)\n",
    "FR_cum['date'] = pd.to_datetime(FR_cum['date'], format='%Y%m%d')\n",
    "# Create a plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add each line plot for each FR column\n",
    "if sel_freq!= None:\n",
    "    cum_plot_cols = [col for col in FR_cols if col.endswith(str(sel_freq))]\n",
    "else:\n",
    "    cum_plot_cols = FR_cols\n",
    "    \n",
    "for FR_col in cum_plot_cols:\n",
    "    fig.add_trace(go.Scatter(x=FR_cum['date'], y=FR_cum[FR_col], mode='lines', name=FR_col))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=FR_cum['date'], y=FR_cum['new_alpha_linear_FR_ret60'] - FR_cum['alpha_FR_ret60'], mode='lines', name='Improvement'))\n",
    "# fig.add_trace(go.Scatter(x=FR_cum['date'], y=FR_cum['MI_0.5_FR_ret60'] - FR_cum['tf.ABmaxshs_FR_ret60'], mode='lines', name='compare'))\n",
    "\n",
    "# Add a vertical dashed line at end_train_date\n",
    "fig.add_shape(\n",
    "    go.layout.Shape(\n",
    "        type='line',\n",
    "        x0=pd.to_datetime(end_train_date, format='%Y%m%d'),\n",
    "        x1=pd.to_datetime(end_train_date, format='%Y%m%d'),\n",
    "        y0=0,\n",
    "        y1=FR_cum.iloc[-1, 1:].max(),\n",
    "        xref='x',\n",
    "        yref='paper',\n",
    "        line=dict(color='black', dash='dash')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update the layout of the figure\n",
    "fig.update_layout(\n",
    "    title='Cumulative Sum of FR Columns',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Cumulative Sum',\n",
    "    showlegend=True,\n",
    "    legend_title_text='FR Columns'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "print(FR_cum['new_alpha_linear_FR_ret60'].iloc[-1] /FR_cum['alpha_FR_ret60'].iloc[-1] -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of.B_A_diff_max.lvl\n",
      "new_alpha_linear\n",
      "tf.RetM\n",
      "cf.B_A_diff_norders\n",
      "alpha\n",
      "tf.B_A_diff_max.age_exp_neg_lvl\n",
      "mtni\n",
      "mti\n",
      "PDN\n",
      "cf.ABmaxshsdiff\n",
      "tf.B_A_diff_notl\n",
      "OPD\n",
      "cf.B_A_diff_max.age_exp_neg_lvl\n",
      "tf.B_A_diff_max.age\n",
      "of.B_A_diff_max.notl\n",
      "tf.B_A_diff_norders\n",
      "mtnid\n",
      "tf.ABMPrcD\n",
      "tf.B_A_diff_max.notl\n",
      "coIO\n",
      "bk.ABD1\n",
      "CPD\n",
      "bk.ABR2\n",
      "of.B_A_diff_norders\n",
      "cf.B_A_diff_notl\n",
      "of.B_A_diff_max.age_exp_neg_lvl\n",
      "cf.B_A_diff_max.age_exp_neg\n",
      "OI2\n",
      "tf.ABmaxshsdiff\n",
      "tf.B_A_diff_max.shs\n",
      "of.B_A_diff_max.age_exp_neg\n",
      "OI1\n",
      "bk.mid_price_var_1m\n",
      "tf.B_A_diff_max.age_exp_neg\n",
      "of.B_A_diff_max.age\n",
      "PDG\n",
      "of.B_A_diff_max.shs\n",
      "of.B_A_diff_notl\n",
      "of.ABmaxshsdiff\n",
      "cf.B_A_diff_max.lvl\n",
      "PDG2\n",
      "PDM\n",
      "tf.B_A_diff_max.lvl\n",
      "cf.B_A_diff_max.shs\n",
      "cf.B_A_diff_max.age\n",
      "cf.B_A_diff_max.notl\n",
      "tf.DPrcRGL1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_12.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "for test_col in test_cols:\n",
    "    collect_cum = []\n",
    "    for col in [col for col in FR_cum.columns if col.startswith(test_col)]:\n",
    "        collect_cum.append((int(col.split('ret')[-1]), FR_cum[col].iloc[-1]))\n",
    "    collect_cum = sorted(collect_cum, key=lambda x: x[0])\n",
    "    x_vals = [item[0] for item in collect_cum]\n",
    "    y_vals = [item[1] for item in collect_cum]\n",
    "\n",
    "    # Add the line plot\n",
    "    fig.add_trace(go.Scatter(x=x_vals, y=y_vals, mode='lines', name=f'Cumulative Sum of {test_col}'))\n",
    "    print(test_col)\n",
    "\n",
    "# Update the layout of the figure\n",
    "fig.update_layout(\n",
    "    title='Cumulative Sum for Different Time Windows',\n",
    "    xaxis_title='Time Window',\n",
    "    yaxis_title='Cumulative Sum',\n",
    "    showlegend=True,\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### timezome change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'values' has incorrect type (expected numpy.ndarray, got Series)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-fce457ed28b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m### select conditions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhkt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimezone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Asia/Hong_Kong'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rec_epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rec_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m's'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz_localize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'UTC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhkt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/nas2Data/apps/anaconda3/lib/python3.7/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m    828\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_and_box_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/nas2Data/apps/anaconda3/lib/python3.7/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             result, tz_parsed = tslib.array_with_unit_to_datetime(\n\u001b[0;32m--> 346\u001b[0;31m                 \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             )\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument 'values' has incorrect type (expected numpy.ndarray, got Series)"
     ]
    }
   ],
   "source": [
    "from pytz import timezone\n",
    "\n",
    "### select conditions\n",
    "hkt = timezone('Asia/Hong_Kong')\n",
    "df['rec_epoch'] = pd.to_datetime(df['rec_epoch'], unit = 's').dt.tz_localize('UTC').dt.tz_convert(hkt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
